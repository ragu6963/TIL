## 10.2 케라스로 다층 퍼셉트론 구현

### 10.2.2 이미지 분류기 만들기

> tensorflow 와 keras import

```python
import tensorflow as tf
from tensorflow import keras
print(tf.__version__)
print(keras.__version__)
```

> 케라스를 사용하여 데이터셋 적재

```python
fashion_mnist = keras.datasets.fashion_mnist
(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()
print(X_train_full.shape) # (60000, 28, 28)
print(X_train_full.dtype) # uint8
```

> 데이터셋 0 ~ 1로 정규화 및 훈련 세트와 테스트 세트로 나누기

```python
X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0
y_valid, y_train = y_train_full[:5000], y_train_full[5000:]
X_test = X_test / 255.0
```

> 클래스 이름 리스트 생성

```python
class_names = ["T-shirt/top","Trouser","Pullover","Dress","Coat","Sandal","Shirt","Sneaker","Bag","Ankle boot"]
print(class_names[y_train[0]]) # Coat
```

> 시퀀셜 API로 모델 만들기

```python
# 시퀀설 모델 생성 : 순서대로 연결된 층을 일렬로 쌓는 구성
model = keras.models.Sequential()

# Flatten : 입력 이미지를 1차원으로 펼치기
model.add(keras.layers.Flatten(input_shape=[28, 28]))

# 300개의 뉴런을 가진 은닉층 추가. 활성화 함수 ReLU.
# 가중치 및 편향을 관리한다.
model.add(keras.layers.Dense(300, activation="relu"))

# 100개의 뉴런을 가진 은닉층 추가. 활성화 함수 ReLU.
model.add(keras.layers.Dense(100, activation="relu"))

# 10개의 뉴런을 가진 출력층 추가. 출력 함수 softmax
model.add(keras.layers.Dense(10, activation="softmax"))

# 모델의 모든 층 출력
model.summary()

```

> 모델 컴파일

```python
# 손실함수, 최적화방법, 평가 지표 설정
model.compile(loss="sparse_categorical_crossentropy", optimizer="sgd", metrics=["accuracy"])
```

> 모델 훈련과 평가

```python
# 입력 특성, 타깃 클래스, 훈련할 에포크 횟수, 검증 세트(선택 사항)
history = model.fit(X_train, y_train, epochs=30, validation_data = (X_valid, y_valid))
"""
# 훈련 경과, 훈련세트에 대한 손실 함수, 훈련세트에 대한 측정지표, 검증세트에 대한 손실함수, 검증세트에 대한 측정지표 
Epoch 30/30
1719/1719 [==============================] - 5s 3ms/step - loss: 0.2261 - accuracy: 0.9190 - val_loss: 0.3241 - val_accuracy: 0.8882
"""
```

### 10.2.3 시퀀셜 API를 사용하여 회귀용 다층 퍼셉트론 만들기

> 캘리포니아 주택가격 데이터셋으로 회귀 신경망 구현

```python
# 데이터 불러오기
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

housing = fetch_california_housing()

# 데이터셋 나누기
X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)
X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)

# 정규화
scaler = StandardScaler()
x_train = scaler.fit_transform(X_train)
X_valid = scaler.transform(X_valid)
X_test = scaler.transform(X_test)    

# 모델 설계
from tensorflow import keras
model = keras.models.Sequential([
    keras.layers.Dense(30, activation="relu", input_shape = X_train.shape[1:]),
    keras.layers.Dense(1)
])
model.compile(loss="mean_squared_error", optimizer="sgd")

# 모델 훈련
history = model.fit(X_train, y_train, epochs = 20, validation_data=(X_valid,y_valid))

# 모델 평가
mse_test = model.evaluate(X_test, y_test)

# 모델 추론
X_new = X_test[:3]
y_pred = model.predict(X_new)
```

---

### 10.2.4 함수형 API를 사용해 복잡한 모델 만들기

순차적이지 않은 신경망의 한 예는 `와이드 & 딥`신경망이 있다.

```python
# 입력층
input_ = keras.layers.Input(shape=X_train.shape[1:])

# 은닉층 1,2 
hidden1 = keras.layers.Dense(30, activation="relu")(input_)
hidden2 = keras.layers.Dense(30, activation="relu")(hidden1)

# 층 연결
concat = keras.layers.Concatenate()([input_,hidden2])

# 출력층
output = keras.layers.Dense(1)(concat)
model = keras.Model(inputs=[input_], outputs=[output])
```

> 5개의 특성은 짧은 경로로 보내고, 6개의 특성은 깊은 경로로 보내는 과정

```python
input_A = keras.layers.Input(shape=[5], name="wide_input")
input_B = keras.layers.Input(shape=[6], name="deep_input")
hidden1 = keras.layers.Dense(30, activation="relu")(input_B)
hidden2 = keras.layers.Dense(30, activation="relu")(hidden1)
concat = keras.layers.Concatenate()([input_A,hidden2])
output = keras.layers.Dense(1, name="output")(concat)
# 두 개의 입력
model= keras.Model(inputs=[input_A,input_B],outputs=[output])

# ---
model.compile(loss = "mse", optimizer=keras.optimizers.SGD(lr=1e-3))

X_train_A, X_train_B =  X_train[:,:5],X_train[:,2:]
X_valid_A, X_valid_B =  X_valid[:,:5],X_valid[:,2:]

X_test_A, X_test_B =  X_test[:,:5],X_test[:,2:]
X_new_A, X_new_B =  X_new[:,:5],X_new[:,2:]

# 학습, 평가, 추론 시에도 2개의 입력
history = model.fit((X_train_A,X_train_B), y_train, epochs = 20, validation_data=((X_valid_A, X_valid_B), y_valid))
mse_test = model.evaluate((X_test_A,X_test_B),y_test)
y_pred = model.predict((X_new_A,X_new_B))
```

