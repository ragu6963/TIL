> 도서 : 밑바닥 부터 시작하는 딥러닝 [도서](https://www.hanbit.co.kr/store/books/look.php?p_code=B8475831198) [깃허브](https://github.com/WegraLee/deep-learning-from-scratch)

# 7장 합성곱 신경망(CNN)

## 7.1 전체 구조

`CNN`도 지금까지와의 신경망 같이 레고 블록처럼 계층을 조립하여 만든다. 

다만, `합성곱 계층(convolutional layer)`와 `풀링 계층(pooling layer)` 이 새롭게 등장한다.

지금까지의 신경망은 인접하는 계층의 모든 뉴런과 결합되어 있었다.

이를 `완전연결(fully-connected)`라고 하며, `Affine 계층`이라는 이름으로 구현했다.

> `Affine 계층`을 사용한 층이 5개인 완전연결 신경망

<img src="7징_합성곱 신경망(CNN).assets/fig 7-1.png">



`완전연결 신경망`은 Affine 계층 뒤에 활성화 함수 계층(ReLU or Sigmoid)이 이어진다.

>  `CNN 구조`

<img src="7징_합성곱 신경망(CNN).assets/fig 7-2.png">

`CNN 계층`은 `Conv-ReLU-(Pooling)`의 흐름으로 연결된다.(풀링 계층은 생략되기도 한다.)

그림에서 주목할 점은 출력에 가까운 층에서는 `Affine-ReLU`를 사용할 수 있고, 마지막 출력 계층에서는 `Affine-Softmax`조합을 그대로 사용한다는 점이다.

## 7.2 합성곱 계층

CNN에서는 `패딩(padding),스트라이드(strid)` 등 고유의 용어가 등장한다.

또한, 각 계층 사이에서 3차원 데이터같은 `입체적인 데이터`가 흐른다는 점이 완전연결 신경망과 다르다.

### 7.2.1 완전연결 계층의 문제점

완전연결 계층의 문제점은 `데이터의 형상이 무시`된다는 점이다.

예를들어 이미지 데이터의 경우 세로 가로 채널로 구성된 3차원 데이터이다. 그러나 완전연결 계층에 입력할 떄는 1차원 데이터로 평탄화`flat`해줘야 한다.

이미지는 3차원 형상이며, 이 형상에는 `공간적 정보`가 담겨있지만 완전연결 계층은 이 형상을 무시하기 때문에 정보를 살릴 수 없다.

반면, `합성곱 계층`은 형상을 유지한다. 이미지는 3차원 데이터로 입력받고, 3차원 데이터를 전달한다.

CNN 에서는 합성곱 계층의 입출력 데이터를 `특징 맵feature map` , 입력 데이터는 `입력 특징 맵` 출력 데이터는 `출력 특징 맵`이라고도 한다.

### 7.2.2 합성곱 연산

합성곱 계층에서` 합성곱 연산`을 처리한다. 이미지 처리에서는 `필터 연산`에 해당한다.

> 합성곱 연산 예

<img src="7징_합성곱 신경망(CNN).assets/fig 7-3.png">

입력 데이터와 필터는 세로 가로의 형상을 가진다. 세로와 가로는 `높이 height`, `너비 width`로 표현한다.  필터는 `커널`이라고도 부른다.

예시에서는 입력 데이터는 (4,4), 필터는 (3,3), 출력은 (2,2) 이다.

---

합성곱 연산은 필터의 `윈도우`를 일정 간격으로 이동해가며 입력 데이터에 적용한다. 여기서 윈도우는 그림의 회색 3 X 3이다.

> 합성곱 연산의 계산 순서

<img src="7징_합성곱 신경망(CNN).assets/fig 7-4.png">

완전연결 신경망에는 가중치와 편향이 존재하는데 CNN에서는 `필터`가 `가중치`에 해당한다. 또한, CNN에도 편향이 존재한다.

> 합성곱 연상에서의 편향

<img src="7징_합성곱 신경망(CNN).assets/fig 7-5.png">

### 7.2.3 패딩

합성곱 연산을 수행하기 전에 입력 데이터 주변을 특정 값(0, etc...)으로 채우기도 한다. 

이것을 `패딩 padding`이라고 한다.

예를들면 아래 그림은 (4,4) 크기의 입력 데이터에 폭 1의 패딩을 적용한 것이다.

> 폭 1칸을 0으로 채웠다.

<img src="7징_합성곱 신경망(CNN).assets/fig 7-6.png">

(4,4) 크기에 패딩을 적용해서 (6,6)이 됐고, (3,3) 필터를 적용해서 (4,4) 크기의 출력 데이터를 얻었다.

> 패딩은 주로 출력 데이터의 크기를 조정할 목적으로 사용한다. 만약 (4,4) 입력에 (3,3) 필터를 적용하면 (2,2) 출력이 나온다. 합성곱 연산을 여러번하는 신경망에서는 언젠가 크기가 1이 돼버리고, 합성곱 연산을 적용할 수 없게된다. 이러한 현상을 방지하기위해 패딩을 적용한다.

### 7.2.4 스트라이드

필터를 적용하는 위치 간격을 `스트라이드stride`라고 한다. 지금까지의 예시는 스트라이드가 모두 1이였다.

> 스트라이드가 2일 때 그림

<img src="7징_합성곱 신경망(CNN).assets/fig 7-7.png">

예시에서 스트라이드를 2로 적용 하니 출력이 (3,3)이 됐다. 이처럼 스트라이드를 키우면 출력 크기가 작아진다.

패딩을 키우면 출력 크기가 커지고, 스트라이드를 키우면 출력 크기가 작아진다.  이것을 수식화 하면 아래처럼 된다. 

입력 크기를 (H,W) 필터 크기를 (FH,FW) 출력 크기를 (OH,OW) 패딩을 P 스트라이드가 S 이다.

<img src="7징_합성곱 신경망(CNN).assets/e 7.1.png">

### 7.2.5 3차원 데이터의 합성곱 연산

지금까지는 2차원 데이터의 합성곱 연산이였다. 3차원 데이터의 합성곱 연산을 알아보자.

<img src="7징_합성곱 신경망(CNN).assets/fig 7-8.png">

채널쪽으로 특징 맵이 여러 개라면 입력 데이터와 필터의 합성곱 연산을 채널마다 수행해서 결과를 더해서 하나의 출력을 얻는다.

3차원의 합성곱 연산에서 주의할 점은 입력 데이터의 `채널 수`와 필터의 `채널 수`가 같아야 한다는 것이다. 위 그림에서는 3개로 일치한다.

한편, 필터 제체의 크기는 원하는 값으로 설정할 수 있다.

### 7.2.6 블록으로 생각하기

