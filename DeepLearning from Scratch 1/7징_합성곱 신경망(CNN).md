> 도서 : 밑바닥 부터 시작하는 딥러닝 [도서](https://www.hanbit.co.kr/store/books/look.php?p_code=B8475831198) [깃허브](https://github.com/WegraLee/deep-learning-from-scratch)

# 7장 합성곱 신경망(CNN)

## 7.1 전체 구조

`CNN`도 지금까지와의 신경망 같이 레고 블록처럼 계층을 조립하여 만든다. 

다만, `합성곱 계층(convolutional layer)`와 `풀링 계층(pooling layer)` 이 새롭게 등장한다.

지금까지의 신경망은 인접하는 계층의 모든 뉴런과 결합되어 있었다.

이를 `완전연결(fully-connected)`라고 하며, `Affine 계층`이라는 이름으로 구현했다.

> `Affine 계층`을 사용한 층이 5개인 완전연결 신경망

<img src="7징_합성곱 신경망(CNN).assets/fig 7-1.png">



`완전연결 신경망`은 Affine 계층 뒤에 활성화 함수 계층(ReLU or Sigmoid)이 이어진다.

>  `CNN 구조`

<img src="7징_합성곱 신경망(CNN).assets/fig 7-2.png">

`CNN 계층`은 `Conv-ReLU-(Pooling)`의 흐름으로 연결된다.(풀링 계층은 생략되기도 한다.)

그림에서 주목할 점은 출력에 가까운 층에서는 `Affine-ReLU`를 사용할 수 있고, 마지막 출력 계층에서는 `Affine-Softmax`조합을 그대로 사용한다는 점이다.

## 7.2 합성곱 계층

CNN에서는 `패딩(padding),스트라이드(strid)` 등 고유의 용어가 등장한다.

또한, 각 계층 사이에서 3차원 데이터같은 `입체적인 데이터`가 흐른다는 점이 완전연결 신경망과 다르다.

### 7.2.1 완전연결 계층의 문제점

완전연결 계층의 문제점은 `데이터의 형상이 무시`된다는 점이다.

예를들어 이미지 데이터의 경우 세로 가로 채널로 구성된 3차원 데이터이다. 그러나 완전연결 계층에 입력할 떄는 1차원 데이터로 평탄화`flat`해줘야 한다.

이미지는 3차원 형상이며, 이 형상에는 `공간적 정보`가 담겨있지만 완전연결 계층은 이 형상을 무시하기 때문에 정보를 살릴 수 없다.

 